{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mahotas in /opt/conda/lib/python3.6/site-packages\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from mahotas)\n",
      "Requirement already satisfied: ndparse in /opt/conda/lib/python3.6/site-packages\n"
     ]
    }
   ],
   "source": [
    "# Synapse Classification Challenge\n",
    "# Introduction to Connectomics 2018\n",
    "# Elliot Yang Liu (your name here)\n",
    "\n",
    "your_name = 'liu_elliot'\n",
    "!pip install mahotas\n",
    "!pip install ndparse\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "data = np.load('./synchallenge2017_training.npz')\n",
    "\n",
    "imtrain = data['imtrain']\n",
    "annotrain = data['annotrain']\n",
    "ytrain = data['ytrain']\n",
    "\n",
    "data = np.load('./synchallenge2017_validation.npz')\n",
    "\n",
    "imvalid = data['imvalid']\n",
    "annovalid = data['annovalid']\n",
    "yvalid = data['yvalid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature extraction code\n",
    "\n",
    "import skimage.feature as skif\n",
    "\n",
    "def extract_features(imdata):\n",
    "    xtrain = []\n",
    "    for im in imdata:\n",
    "        fvector = []\n",
    "        # 35th percentile based on intensity\n",
    "        fvector.append(np.percentile(im,35))\n",
    "       \n",
    "        \n",
    "        # add a contrast feature\n",
    "        g = skif.greycomatrix(im, [1, 3], [0, np.pi/2],normed=True, symmetric=True)\n",
    "        homogeneity = skif.greycoprops(g, 'homogeneity')\n",
    "\n",
    "        # explict way to add feature elements one at a time\n",
    "        homogeneity = np.ravel(homogeneity)\n",
    "        for i in homogeneity:\n",
    "            fvector.append(i)\n",
    "            \n",
    "        #fvector.append(skif.blob_dog(im))\n",
    "        #blob = np.ravel(skif.blob_dog(im))\n",
    "        #for i in blob:\n",
    "        #    fvector.append(i)\n",
    "        \n",
    "        #fvector.append(skif.shape_index(im))\n",
    "        \n",
    "        #fvector.append(skif.hessian_matrix_det(im, sigma = 1))\n",
    "        #hess = skif.hessian_matrix_det(im, sigma = 1)\n",
    "        #hess = np.ravel(hess)\n",
    "        #for k in hess:\n",
    "        #   fvector.append(k)\n",
    "\n",
    "        canny = skif.canny(im, sigma = 1000)\n",
    "        canny = np.ravel(canny)\n",
    "        for j in canny:\n",
    "            fvector.append(j)\n",
    "\n",
    "        fvector = np.asarray(fvector)\n",
    "        xtrain.append(fvector)\n",
    "        \n",
    "\n",
    "        \n",
    "    return np.asarray(xtrain)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-8c6e48f1c595>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Extract Features from training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mxtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m# Train Classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-d8a172e2205c>\u001b[0m in \u001b[0;36mextract_features\u001b[0;34m(imdata)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mfvector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfvector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mxtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfvector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Extract Features from training\n",
    "\n",
    "xtrain = extract_features(imtrain)\n",
    "# Train Classifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=200)\n",
    "clf = clf.fit(xtrain, ytrain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features from validation set\n",
    "xvalid = extract_features(imvalid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Classifier on validation set\n",
    "scoresvalid = clf.predict_proba(xvalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best f1 score report on validation set\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Can add post-processing here if desired\n",
    "\n",
    "prob_syn = scoresvalid[:,1]\n",
    "\n",
    "# default threshold\n",
    "print('default f1 score: {}'.format(np.round(f1_score(yvalid, prob_syn >=0.5),2)))\n",
    "\n",
    "f1_out = 0\n",
    "thresh = 0\n",
    "for i in np.arange(0.0, 1, 0.05):\n",
    "    f1_test =  f1_score(yvalid, prob_syn > i)\n",
    "    if f1_test > f1_out:\n",
    "        f1_out = f1_test\n",
    "        thresh = i\n",
    "\n",
    "print('My best validation f1-score is: {} at {} threshold.'.format(np.round(f1_out,2), thresh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we can inspect results\n",
    "\n",
    "valid_labels = np.asarray(prob_syn > thresh,dtype='int')\n",
    "# find images we did well on\n",
    "idx_correct_syn = np.where((valid_labels == yvalid) & (yvalid == 1))[0]\n",
    "idx_correct_nosyn = np.where((valid_labels == yvalid) & (yvalid == 0))[0]\n",
    "# find images we did poorly on\n",
    "\n",
    "idx_wrong_syn = np.where((valid_labels != yvalid) & (yvalid == 1))[0]\n",
    "idx_wrong_nosyn = np.where((valid_labels != yvalid) & (yvalid == 0))[0]\n",
    "import ndparse as ndp\n",
    "\n",
    "print('synapse present - true positive')\n",
    "ndp.plot(imvalid[idx_correct_syn[3]])\n",
    "\n",
    "print('no synapse present - true negative')\n",
    "ndp.plot(imvalid[idx_correct_nosyn[3]])\n",
    "\n",
    "print('synapse present - false negative')\n",
    "ndp.plot(imvalid[idx_wrong_syn[3]])\n",
    "\n",
    "print('no synapse present - false positive')\n",
    "ndp.plot(imvalid[idx_wrong_nosyn[3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate performance on test set (should only run/score once!)\n",
    "\n",
    "data = np.load('./synchallenge2017_test_notruth.npz')\n",
    "\n",
    "imtest = data['imtest']\n",
    "annotest = data['annotest']\n",
    "\n",
    "# Extract features from test set\n",
    "xtest = extract_features(imtest)\n",
    "\n",
    "# Run classifier on test set\n",
    "scoretest = clf.predict_proba(xvalid)\n",
    "\n",
    "# Post-processing\n",
    "prob_syntest = scoretest[:,1]\n",
    "syntest_predict = prob_syntest > thresh\n",
    "syntest_predict = np.asarray(syntest_predict,dtype = 'uint8')\n",
    "\n",
    "# save file and upload to google docs with label vector\n",
    "np.save(your_name+'_synchallenge_testdata.npy',syntest_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
