{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#The main portion of this code was taken from the below license. In addition to their detailed instructions, modifications\n",
    "#were made to make it work with our data sets and to modify some of their algorithm.\n",
    "\n",
    "#Note, this does run on docker as the data sets are smaller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MIT License\n",
    "\n",
    "#Copyright (c) 2017 Ankit Sachan\n",
    "\n",
    "#Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "#of this software and associated documentation files (the \"Software\"), to deal\n",
    "#in the Software without restriction, including without limitation the rights\n",
    "#to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "#copies of the Software, and to permit persons to whom the Software is\n",
    "#furnished to do so, subject to the following conditions:\n",
    "\n",
    "#The above copyright notice and this permission notice shall be included in all\n",
    "#copies or substantial portions of the Software."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mahotas\n",
      "  Downloading mahotas-1.4.4.tar.gz (1.5MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.5MB 456kB/s eta 0:00:01    91% |█████████████████████████████▏  | 1.4MB 35.4MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from mahotas)\n",
      "Building wheels for collected packages: mahotas\n",
      "  Running setup.py bdist_wheel for mahotas ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jovyan/.cache/pip/wheels/76/87/24/2ffb31d56c7d1f21175c006697cb7e305a43fe0be0891cfdc8\n",
      "Successfully built mahotas\n",
      "Installing collected packages: mahotas\n",
      "Successfully installed mahotas-1.4.4\n",
      "Collecting ndparse\n",
      "  Downloading ndparse-0.0.7.tar.gz\n",
      "Building wheels for collected packages: ndparse\n",
      "  Running setup.py bdist_wheel for ndparse ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jovyan/.cache/pip/wheels/1f/3b/63/8d99427fa5243ad5490f37c5dfbb78fc3153e07faafa12cd5e\n",
      "Successfully built ndparse\n",
      "Installing collected packages: ndparse\n",
      "Successfully installed ndparse-0.0.7\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-1.4.1-cp36-cp36m-manylinux1_x86_64.whl (41.2MB)\n",
      "\u001b[K    100% |████████████████████████████████| 41.2MB 12kB/s eta 0:00:011  1% |▌                               | 593kB 7.4MB/s eta 0:00:06    2% |█                               | 1.2MB 8.5MB/s eta 0:00:05    6% |██                              | 2.7MB 14.6MB/s eta 0:00:03    7% |██▌                             | 3.3MB 6.2MB/s eta 0:00:07    12% |████                            | 5.3MB 17.7MB/s eta 0:00:03    18% |█████▉                          | 7.5MB 12.8MB/s eta 0:00:03    23% |███████▌                        | 9.7MB 11.7MB/s eta 0:00:03    25% |████████                        | 10.3MB 12.3MB/s eta 0:00:03    26% |████████▋                       | 11.1MB 25.3MB/s eta 0:00:02    41% |█████████████▏                  | 17.0MB 15.5MB/s eta 0:00:02    53% |█████████████████               | 22.0MB 8.5MB/s eta 0:00:03    56% |██████████████████▎             | 23.5MB 17.0MB/s eta 0:00:02    85% |███████████████████████████▍    | 35.2MB 13.5MB/s eta 0:00:01    87% |████████████████████████████    | 36.0MB 4.5MB/s eta 0:00:02    92% |█████████████████████████████▋  | 38.2MB 6.4MB/s eta 0:00:01    96% |██████████████████████████████▉ | 39.8MB 11.0MB/s eta 0:00:01    98% |███████████████████████████████▍| 40.5MB 23.0MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.6/site-packages (from tensorflow)\n",
      "Collecting tensorflow-tensorboard<0.5.0,>=0.4.0rc1 (from tensorflow)\n",
      "  Downloading tensorflow_tensorboard-0.4.0-py3-none-any.whl (1.7MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.7MB 270kB/s ta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow)\n",
      "Requirement already satisfied: numpy>=1.12.1 in /opt/conda/lib/python3.6/site-packages (from tensorflow)\n",
      "Collecting enum34>=1.1.6 (from tensorflow)\n",
      "  Downloading enum34-1.1.6-py3-none-any.whl\n",
      "Requirement already satisfied: protobuf>=3.3.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow)\n",
      "Collecting werkzeug>=0.11.10 (from tensorflow-tensorboard<0.5.0,>=0.4.0rc1->tensorflow)\n",
      "  Downloading Werkzeug-0.14.1-py2.py3-none-any.whl (322kB)\n",
      "\u001b[K    100% |████████████████████████████████| 327kB 1.2MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting html5lib==0.9999999 (from tensorflow-tensorboard<0.5.0,>=0.4.0rc1->tensorflow)\n",
      "  Downloading html5lib-0.9999999.tar.gz (889kB)\n",
      "\u001b[K    100% |████████████████████████████████| 890kB 495kB/s eta 0:00:01    23% |███████▍                        | 204kB 8.5MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting markdown>=2.6.8 (from tensorflow-tensorboard<0.5.0,>=0.4.0rc1->tensorflow)\n",
      "  Downloading Markdown-2.6.11-py2.py3-none-any.whl (78kB)\n",
      "\u001b[K    100% |████████████████████████████████| 81kB 2.7MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting bleach==1.5.0 (from tensorflow-tensorboard<0.5.0,>=0.4.0rc1->tensorflow)\n",
      "  Downloading bleach-1.5.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.6/site-packages (from protobuf>=3.3.0->tensorflow)\n",
      "Building wheels for collected packages: html5lib\n",
      "  Running setup.py bdist_wheel for html5lib ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jovyan/.cache/pip/wheels/6f/85/6c/56b8e1292c6214c4eb73b9dda50f53e8e977bf65989373c962\n",
      "Successfully built html5lib\n",
      "Installing collected packages: werkzeug, html5lib, markdown, bleach, tensorflow-tensorboard, enum34, tensorflow\n",
      "  Found existing installation: html5lib 1.0.1\n",
      "    Uninstalling html5lib-1.0.1:\n",
      "      Successfully uninstalled html5lib-1.0.1\n",
      "  Found existing installation: bleach 2.0.0\n",
      "    Uninstalling bleach-2.0.0:\n",
      "      Successfully uninstalled bleach-2.0.0\n",
      "Successfully installed bleach-1.5.0 enum34-1.1.6 html5lib-0.9999999 markdown-2.6.11 tensorflow-1.4.1 tensorflow-tensorboard-0.4.0 werkzeug-0.14.1\n"
     ]
    }
   ],
   "source": [
    "your_name = 'perry_ronan'\n",
    "\n",
    "!pip install mahotas\n",
    "!pip install ndparse\n",
    "!pip install tensorflow\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: networkx==1.9 in /opt/conda/lib/python3.6/site-packages\n",
      "Requirement already satisfied: decorator>=3.4.0 in /opt/conda/lib/python3.6/site-packages (from networkx==1.9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "!pip install networkx==1.9 #networkx broke backwards compatibility with these graph files\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import csv\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from skimage.feature import daisy\n",
    "from skimage import data\n",
    "\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/SWU4/desikan\n",
      "Datasets: SWU4 (454)\n",
      "Total Subjects: 454\n"
     ]
    }
   ],
   "source": [
    "# Initializing dataset names\n",
    "dataset_names = 'SWU4'\n",
    "\n",
    "basepath = 'data'\n",
    "\n",
    "# change which atlas you use, here!\n",
    "\n",
    "atlas = 'desikan' # 'desikan' # or 'CPAC200', or 'Talairach'\n",
    "dir_names = basepath + '/' + dataset_names + '/' + atlas\n",
    "#basepath = \"/\"\n",
    "#dir_names = basepath\n",
    "print(dir_names)\n",
    "fs = OrderedDict()\n",
    "fs[dataset_names] = [root + \"/\" + fl for root, dirs, files in os.walk(dir_names)\n",
    "                     for fl in files if fl.endswith(\".gpickle\")]\n",
    "\n",
    "ps = \"data/SWU4/SWU4.csv\"\n",
    "\n",
    "print(\"Datasets: \" + \", \".join([fkey + \" (\" + str(len(fs[fkey])) + \")\"\n",
    "                                for fkey in fs]))\n",
    "print(\"Total Subjects: %d\" % (sum([len(fs[key]) for key in fs])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadGraphs(filenames, verb=False):\n",
    "    \"\"\"\n",
    "    Given a list of files, returns a dictionary of graphs\n",
    "\n",
    "    Required parameters:\n",
    "        filenames:\n",
    "            - List of filenames for graphs\n",
    "    Optional parameters:\n",
    "        verb:\n",
    "            - Toggles verbose output statements\n",
    "    \"\"\"\n",
    "    #  Initializes empty dictionary\n",
    "    gstruct = OrderedDict()\n",
    "    for idx, files in enumerate(filenames):\n",
    "        if verb:\n",
    "            print(\"Loading: \" + files)\n",
    "        #  Adds graphs to dictionary with key being filename\n",
    "        fname = os.path.basename(files)\n",
    "        gstruct[fname] = nx.read_gpickle(files)\n",
    "    return gstruct\n",
    "\n",
    "def constructGraphDict(names, fs, verb=False):\n",
    "    \"\"\"\n",
    "    Given a set of files and a directory to put things, loads graphs.\n",
    "\n",
    "    Required parameters:\n",
    "        names:\n",
    "            - List of names of the datasets\n",
    "        fs:\n",
    "            - Dictionary of lists of files in each dataset\n",
    "    Optional parameters:\n",
    "        verb:\n",
    "            - Toggles verbose output statements\n",
    "    \"\"\"\n",
    "    #  Loads graphs into memory for all datasets\n",
    "    graphs = OrderedDict()\n",
    "    if verb:\n",
    "        print(\"Loading Dataset: \" + names)\n",
    "    # The key for the dictionary of graphs is the dataset name\n",
    "    graphs[names] = loadGraphs(fs[names], verb=verb)\n",
    "    return graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs = constructGraphDict(dataset_names, fs, verb=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "# This gets age and sex, respecitvely.\n",
    "tmp = csv.reader(open(ps,newline='')) # this is the whole phenotype file\n",
    "pheno = OrderedDict()\n",
    "triple = [[t[0].strip(), t[2], int(t[3] == '2')] for t in tmp\n",
    "          if t[3] != '#' and t[2] != '#'][1:]  # female=1->0, male=2->1\n",
    "\n",
    "for idx, trip in enumerate(triple):\n",
    "    pheno[trip[0]] = trip[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = sorted(list(graphs['SWU4'].keys()))\n",
    "k_id = list(key[6:11] for key in k)\n",
    "k_id = k_id[0::2]\n",
    "k_g1 = k[0::2]\n",
    "\n",
    "g1 = []\n",
    "for xx in k_g1:\n",
    "    g1.append(graphs['SWU4'][xx])\n",
    "\n",
    "#Create vectors of labels\n",
    "age = list()\n",
    "sex = list()\n",
    "\n",
    "for key in k_id:\n",
    "    sex.append(pheno[key][1])\n",
    "    age.append(pheno[key][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "\n",
    "sex_classes = [[1,0] if i == 0 else [0,1] for i in sex]\n",
    "traindata = [nx.to_numpy_matrix(i, nodelist=sorted(i.nodes())) for i in g1]\n",
    "traindata = np.array([np.array(i) for i in traindata])\n",
    "\n",
    "imtrain = traindata[0:100]\n",
    "ytrain = sex_classes[0:100]\n",
    "\n",
    "imvalid = traindata[100:200]\n",
    "yvalid = sex_classes[100:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "imtrain = imtrain.reshape((np.shape(imtrain)[0],70,70,1))\n",
    "imvalid = imvalid.reshape((np.shape(imvalid)[0],70,70,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tensor Flow classification\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "#Prepare input data\n",
    "classes = ['female','male']\n",
    "num_classes = len(classes)\n",
    "\n",
    "# 20% of the data will automatically be used for validation\n",
    "validation_size = 0.2\n",
    "img_size = 70\n",
    "\n",
    "num_channels = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = tf.Session()\n",
    "x = tf.placeholder(tf.float32, shape=[None, img_size,img_size,num_channels], name='x')\n",
    "\n",
    "## labels\n",
    "y_true = tf.placeholder(tf.float32, shape=[None, num_classes], name='y_true')\n",
    "y_true_cls = tf.argmax(y_true, dimension=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Network graph params\n",
    "filter_size_conv1 = 3\n",
    "num_filters_conv1 = 32\n",
    "\n",
    "filter_size_conv2 = 3\n",
    "num_filters_conv2 = 32\n",
    "\n",
    "filter_size_conv3 = 3\n",
    "num_filters_conv3 = 64\n",
    "    \n",
    "fc_layer_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_weights(shape):\n",
    "    return tf.Variable(tf.truncated_normal(shape, stddev=0.05))\n",
    "\n",
    "def create_biases(size):\n",
    "    return tf.Variable(tf.constant(0.05, shape=[size]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_convolutional_layer(input,\n",
    "                num_input_channels,           \n",
    "                conv_filter_size,        \n",
    "                num_filters):  \n",
    "    \n",
    "    ## We shall define the weights that will be trained using create_weights function.\n",
    "    weights = create_weights(shape=[conv_filter_size, conv_filter_size, num_input_channels, num_filters])\n",
    "    ## We create biases using the create_biases function. These are also trained.\n",
    "    biases = create_biases(num_filters)\n",
    "\n",
    "    ## Creating the convolutional layer\n",
    "    layer = tf.nn.conv2d(input=input,\n",
    "                     filter=weights,\n",
    "                     strides=[1, 1, 1, 1],\n",
    "                     padding='SAME')\n",
    "\n",
    "    layer += biases\n",
    "\n",
    "    ## We shall be using max-pooling.  \n",
    "    layer = tf.nn.max_pool(value=layer,\n",
    "                            ksize=[1, 2, 2, 1],\n",
    "                            strides=[1, 2, 2, 1],\n",
    "                            padding='SAME')\n",
    "    ## Output of pooling is fed to Relu which is the activation function for us.\n",
    "    layer = tf.nn.relu(layer)\n",
    "\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_flatten_layer(layer):\n",
    "    #We know that the shape of the layer will be [batch_size img_size img_size num_channels] \n",
    "    # But let's get it from the previous layer.\n",
    "    layer_shape = layer.get_shape()\n",
    "\n",
    "    ## Number of features will be img_height * img_width* num_channels. But we shall calculate it in place of hard-coding it.\n",
    "    num_features = layer_shape[1:4].num_elements()\n",
    "\n",
    "    ## Now, we Flatten the layer so we shall have to reshape to num_features\n",
    "    layer = tf.reshape(layer, [-1, num_features])\n",
    "\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fc_layer(input,          \n",
    "             num_inputs,    \n",
    "             num_outputs,\n",
    "             use_relu=True):\n",
    "    \n",
    "    #Let's define trainable weights and biases.\n",
    "    weights = create_weights(shape=[num_inputs, num_outputs])\n",
    "    biases = create_biases(num_outputs)\n",
    "\n",
    "    # Fully connected layer takes input x and produces wx+b.Since, these are matrices, we use matmul function in Tensorflow\n",
    "    layer = tf.matmul(input, weights) + biases\n",
    "    if use_relu:\n",
    "        layer = tf.nn.relu(layer)\n",
    "\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_conv1 = create_convolutional_layer(input=x,\n",
    "               num_input_channels=num_channels,\n",
    "               conv_filter_size=filter_size_conv1,\n",
    "               num_filters=num_filters_conv1)\n",
    "\n",
    "layer_conv2 = create_convolutional_layer(input=layer_conv1,\n",
    "               num_input_channels=num_filters_conv1,\n",
    "               conv_filter_size=filter_size_conv2,\n",
    "               num_filters=num_filters_conv2)\n",
    "\n",
    "layer_conv3= create_convolutional_layer(input=layer_conv2,\n",
    "               num_input_channels=num_filters_conv2,\n",
    "               conv_filter_size=filter_size_conv3,\n",
    "               num_filters=num_filters_conv3)\n",
    "          \n",
    "layer_flat = create_flatten_layer(layer_conv3)\n",
    "\n",
    "layer_fc1 = create_fc_layer(input=layer_flat,\n",
    "                     num_inputs=layer_flat.get_shape()[1:4].num_elements(),\n",
    "                     num_outputs=fc_layer_size,\n",
    "                     use_relu=True)\n",
    "\n",
    "layer_fc2 = create_fc_layer(input=layer_fc1,\n",
    "                     num_inputs=fc_layer_size,\n",
    "                     num_outputs=num_classes,\n",
    "                     use_relu=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = tf.nn.softmax(layer_fc2,name='y_pred')\n",
    "\n",
    "y_pred_cls = tf.argmax(y_pred, dimension=1)\n",
    "session.run(tf.global_variables_initializer())\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=layer_fc2,\n",
    "                                                    labels=y_true)\n",
    "cost = tf.reduce_mean(cross_entropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(cost)\n",
    "correct_prediction = tf.equal(y_pred_cls, y_true_cls)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "\n",
    "session.run(tf.global_variables_initializer()) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_progress(epoch, feed_dict_train, feed_dict_validate, val_loss):\n",
    "    acc = session.run(accuracy, feed_dict=feed_dict_train)\n",
    "    val_acc = session.run(accuracy, feed_dict=feed_dict_validate)\n",
    "    msg = \"Training Epoch {0} --- Training Accuracy: {1:>6.1%}, Validation Accuracy: {2:>6.1%},  Validation Loss: {3:.3f}\"\n",
    "    print(msg.format(epoch + 1, acc, val_acc, val_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_iterations = 0\n",
    "saver = tf.train.Saver()\n",
    "def train(num_iteration):\n",
    "    global total_iterations\n",
    "    \n",
    "    for i in range(total_iterations,\n",
    "                   total_iterations + num_iteration):\n",
    "\n",
    "        indices_train = np.random.choice(int(0.8*imtrain.shape[0]), batch_size)\n",
    "        x_batch = imtrain[indices_train]\n",
    "        y_true_batch = [ytrain[i] for i in indices_train]      \n",
    "        \n",
    "        feed_dict_tr = {x: x_batch,\n",
    "                           y_true: y_true_batch}\n",
    "        \n",
    "        offset = int(0.8*imtrain.shape[0])\n",
    "        indices_valid = np.random.choice(int(0.2*imtrain.shape[0]), batch_size)\n",
    "        x_valid_batch = imtrain[indices_valid + offset]\n",
    "        y_valid_batch = [ytrain[i+offset] for i in indices_valid]\n",
    "        \n",
    "        feed_dict_val = {x: x_valid_batch,\n",
    "                              y_true: y_valid_batch}\n",
    "\n",
    "        session.run(optimizer, feed_dict=feed_dict_tr)\n",
    "\n",
    "        if i % int(imtrain.shape[0]/batch_size) == 0: \n",
    "            val_loss = session.run(cost, feed_dict=feed_dict_val)\n",
    "            epoch = int(i / int(imtrain.shape[0]/batch_size)) \n",
    "            \n",
    "            show_progress(epoch, feed_dict_tr, feed_dict_val, val_loss)\n",
    "            saver.save(session, './classify-model') \n",
    "\n",
    "\n",
    "    total_iterations += num_iteration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 1 --- Training Accuracy:  43.8%, Validation Accuracy:  43.8%,  Validation Loss: 86.848\n",
      "Training Epoch 2 --- Training Accuracy:  50.0%, Validation Accuracy:  68.8%,  Validation Loss: 110.527\n",
      "Training Epoch 3 --- Training Accuracy:  53.1%, Validation Accuracy:  21.9%,  Validation Loss: 150.913\n",
      "Training Epoch 4 --- Training Accuracy:  65.6%, Validation Accuracy:  31.2%,  Validation Loss: 41.260\n",
      "Training Epoch 5 --- Training Accuracy:  53.1%, Validation Accuracy:  62.5%,  Validation Loss: 44.631\n",
      "Training Epoch 6 --- Training Accuracy:  62.5%, Validation Accuracy:  81.2%,  Validation Loss: 21.651\n",
      "Training Epoch 7 --- Training Accuracy:  75.0%, Validation Accuracy:  75.0%,  Validation Loss: 19.409\n",
      "Training Epoch 8 --- Training Accuracy:  68.8%, Validation Accuracy:  78.1%,  Validation Loss: 17.822\n",
      "Training Epoch 9 --- Training Accuracy:  75.0%, Validation Accuracy:  65.6%,  Validation Loss: 30.197\n",
      "Training Epoch 10 --- Training Accuracy:  68.8%, Validation Accuracy:  59.4%,  Validation Loss: 42.865\n",
      "Training Epoch 11 --- Training Accuracy:  81.2%, Validation Accuracy:  75.0%,  Validation Loss: 18.987\n",
      "Training Epoch 12 --- Training Accuracy:  75.0%, Validation Accuracy:  75.0%,  Validation Loss: 9.570\n",
      "Training Epoch 13 --- Training Accuracy:  81.2%, Validation Accuracy:  65.6%,  Validation Loss: 38.203\n",
      "Training Epoch 14 --- Training Accuracy:  62.5%, Validation Accuracy:  59.4%,  Validation Loss: 43.073\n",
      "Training Epoch 15 --- Training Accuracy:  81.2%, Validation Accuracy:  75.0%,  Validation Loss: 13.339\n",
      "Training Epoch 16 --- Training Accuracy:  71.9%, Validation Accuracy:  78.1%,  Validation Loss: 12.646\n",
      "Training Epoch 17 --- Training Accuracy:  90.6%, Validation Accuracy:  62.5%,  Validation Loss: 39.240\n",
      "Training Epoch 18 --- Training Accuracy:  87.5%, Validation Accuracy:  87.5%,  Validation Loss: 12.481\n",
      "Training Epoch 19 --- Training Accuracy:  93.8%, Validation Accuracy:  78.1%,  Validation Loss: 18.750\n",
      "Training Epoch 20 --- Training Accuracy:  84.4%, Validation Accuracy:  90.6%,  Validation Loss: 7.978\n",
      "Training Epoch 21 --- Training Accuracy:  93.8%, Validation Accuracy:  78.1%,  Validation Loss: 20.636\n",
      "Training Epoch 22 --- Training Accuracy:  96.9%, Validation Accuracy:  78.1%,  Validation Loss: 13.106\n",
      "Training Epoch 23 --- Training Accuracy:  90.6%, Validation Accuracy:  78.1%,  Validation Loss: 13.616\n",
      "Training Epoch 24 --- Training Accuracy:  96.9%, Validation Accuracy:  71.9%,  Validation Loss: 30.438\n",
      "Training Epoch 25 --- Training Accuracy: 100.0%, Validation Accuracy:  75.0%,  Validation Loss: 12.671\n",
      "Training Epoch 26 --- Training Accuracy:  93.8%, Validation Accuracy:  68.8%,  Validation Loss: 19.753\n",
      "Training Epoch 27 --- Training Accuracy:  93.8%, Validation Accuracy:  65.6%,  Validation Loss: 27.830\n",
      "Training Epoch 28 --- Training Accuracy: 100.0%, Validation Accuracy:  75.0%,  Validation Loss: 8.593\n",
      "Training Epoch 29 --- Training Accuracy:  93.8%, Validation Accuracy:  71.9%,  Validation Loss: 16.486\n",
      "Training Epoch 30 --- Training Accuracy:  96.9%, Validation Accuracy:  65.6%,  Validation Loss: 24.644\n",
      "Training Epoch 31 --- Training Accuracy:  96.9%, Validation Accuracy:  62.5%,  Validation Loss: 14.736\n",
      "Training Epoch 32 --- Training Accuracy:  96.9%, Validation Accuracy:  68.8%,  Validation Loss: 21.101\n",
      "Training Epoch 33 --- Training Accuracy: 100.0%, Validation Accuracy:  65.6%,  Validation Loss: 22.560\n",
      "Training Epoch 34 --- Training Accuracy: 100.0%, Validation Accuracy:  75.0%,  Validation Loss: 16.323\n",
      "Training Epoch 35 --- Training Accuracy:  96.9%, Validation Accuracy:  59.4%,  Validation Loss: 18.521\n",
      "Training Epoch 36 --- Training Accuracy: 100.0%, Validation Accuracy:  84.4%,  Validation Loss: 11.576\n",
      "Training Epoch 37 --- Training Accuracy: 100.0%, Validation Accuracy:  75.0%,  Validation Loss: 17.459\n",
      "Training Epoch 38 --- Training Accuracy: 100.0%, Validation Accuracy:  68.8%,  Validation Loss: 17.212\n",
      "Training Epoch 39 --- Training Accuracy: 100.0%, Validation Accuracy:  84.4%,  Validation Loss: 14.723\n",
      "Training Epoch 40 --- Training Accuracy: 100.0%, Validation Accuracy:  81.2%,  Validation Loss: 11.026\n",
      "Training Epoch 41 --- Training Accuracy: 100.0%, Validation Accuracy:  84.4%,  Validation Loss: 13.147\n",
      "Training Epoch 42 --- Training Accuracy: 100.0%, Validation Accuracy:  75.0%,  Validation Loss: 19.181\n",
      "Training Epoch 43 --- Training Accuracy: 100.0%, Validation Accuracy:  75.0%,  Validation Loss: 12.458\n",
      "Training Epoch 44 --- Training Accuracy: 100.0%, Validation Accuracy:  62.5%,  Validation Loss: 18.793\n",
      "Training Epoch 45 --- Training Accuracy: 100.0%, Validation Accuracy:  56.2%,  Validation Loss: 19.664\n",
      "Training Epoch 46 --- Training Accuracy: 100.0%, Validation Accuracy:  59.4%,  Validation Loss: 18.586\n",
      "Training Epoch 47 --- Training Accuracy: 100.0%, Validation Accuracy:  71.9%,  Validation Loss: 15.791\n",
      "Training Epoch 48 --- Training Accuracy: 100.0%, Validation Accuracy:  75.0%,  Validation Loss: 12.106\n",
      "Training Epoch 49 --- Training Accuracy: 100.0%, Validation Accuracy:  71.9%,  Validation Loss: 13.811\n",
      "Training Epoch 50 --- Training Accuracy: 100.0%, Validation Accuracy:  78.1%,  Validation Loss: 14.045\n",
      "Training Epoch 51 --- Training Accuracy: 100.0%, Validation Accuracy:  87.5%,  Validation Loss: 4.231\n",
      "Training Epoch 52 --- Training Accuracy: 100.0%, Validation Accuracy:  75.0%,  Validation Loss: 13.868\n",
      "Training Epoch 53 --- Training Accuracy: 100.0%, Validation Accuracy:  59.4%,  Validation Loss: 25.400\n",
      "Training Epoch 54 --- Training Accuracy: 100.0%, Validation Accuracy:  59.4%,  Validation Loss: 16.206\n",
      "Training Epoch 55 --- Training Accuracy: 100.0%, Validation Accuracy:  75.0%,  Validation Loss: 13.266\n",
      "Training Epoch 56 --- Training Accuracy: 100.0%, Validation Accuracy:  65.6%,  Validation Loss: 16.206\n",
      "Training Epoch 57 --- Training Accuracy: 100.0%, Validation Accuracy:  56.2%,  Validation Loss: 26.429\n",
      "Training Epoch 58 --- Training Accuracy: 100.0%, Validation Accuracy:  65.6%,  Validation Loss: 18.484\n",
      "Training Epoch 59 --- Training Accuracy: 100.0%, Validation Accuracy:  75.0%,  Validation Loss: 15.999\n",
      "Training Epoch 60 --- Training Accuracy: 100.0%, Validation Accuracy:  68.8%,  Validation Loss: 15.406\n",
      "Training Epoch 61 --- Training Accuracy: 100.0%, Validation Accuracy:  71.9%,  Validation Loss: 19.547\n",
      "Training Epoch 62 --- Training Accuracy: 100.0%, Validation Accuracy:  71.9%,  Validation Loss: 21.714\n",
      "Training Epoch 63 --- Training Accuracy: 100.0%, Validation Accuracy:  65.6%,  Validation Loss: 19.718\n",
      "Training Epoch 64 --- Training Accuracy: 100.0%, Validation Accuracy:  78.1%,  Validation Loss: 14.696\n",
      "Training Epoch 65 --- Training Accuracy: 100.0%, Validation Accuracy:  75.0%,  Validation Loss: 11.912\n",
      "Training Epoch 66 --- Training Accuracy: 100.0%, Validation Accuracy:  71.9%,  Validation Loss: 17.682\n",
      "Training Epoch 67 --- Training Accuracy: 100.0%, Validation Accuracy:  78.1%,  Validation Loss: 14.315\n"
     ]
    }
   ],
   "source": [
    "session.run(tf.global_variables_initializer()) \n",
    "\n",
    "train(num_iteration=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./classify-model\n"
     ]
    }
   ],
   "source": [
    "#Begin Prediciton Portion.\n",
    "\n",
    "#Restore prior saved trained model\n",
    "sess = tf.Session()\n",
    "saver = tf.train.import_meta_graph('classify-model.meta')\n",
    "\n",
    "#Load the weights\n",
    "saver.restore(sess,tf.train.latest_checkpoint('./'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Access learned graph\n",
    "graph = tf.get_default_graph()\n",
    "\n",
    "#In the original network y_pred is the tensor that is the prediction of the network\n",
    "y_pred = graph.get_tensor_by_name(\"y_pred:0\")\n",
    "\n",
    "#Let's feed the images to the input placeholders\n",
    "x= graph.get_tensor_by_name(\"x:0\") \n",
    "y_true = graph.get_tensor_by_name(\"y_true:0\") \n",
    "y_test_images = np.zeros((np.shape(imvalid)[0], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the feed_dict that is required to be fed to calculate y_pred \n",
    "feed_dict_testing = {x: imvalid, y_true: y_test_images}\n",
    "result=sess.run(y_pred, feed_dict=feed_dict_testing)\n",
    "# result is of this format [probabiliy_of_rose probability_of_sunflower]\n",
    "#print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 0.69\n",
      "Best Accuracy: 0.69 at Threshold 0.15\n"
     ]
    }
   ],
   "source": [
    "accuracy = []\n",
    "for ii in range(len(result)): #performance will change over time\n",
    "    acc = ((result[ii,0] > 0.5) == yvalid[ii][0])\n",
    "    #print(acc)\n",
    "    accval = (float(np.sum(acc))/float(len(result)))\n",
    "    accuracy.append(accval)\n",
    "    #print('Accuracy:',accval)\n",
    "\n",
    "print('Overall Accuracy:',str(np.sum(accuracy)))\n",
    "\n",
    "f1_out = 0\n",
    "thresh = 0\n",
    "for i in np.arange(0.0, 1, 0.05):\n",
    "    f1_test = 0\n",
    "    for ii in range(len(result)):\n",
    "        f1_test += ((result[ii,0] > i) == yvalid[ii][0])\n",
    "    f1_test = f1_test / float(len(result))\n",
    "    if f1_test > f1_out:\n",
    "        f1_out = f1_test\n",
    "        thresh = i\n",
    "\n",
    "print(('Best Accuracy: %s at Threshold %s') % (str(f1_out),str(thresh)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
