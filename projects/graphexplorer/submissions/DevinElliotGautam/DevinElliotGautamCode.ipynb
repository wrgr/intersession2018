{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Data\n",
    "\n",
    "First, we want to grab some graphs and subject covariates from a web-accessible url.  We've given this to you on google drive rather than having you set up aws s3 credentials in the interest of saving time. The original data is hosted at m2g.io\n",
    "\n",
    "Below, you will be getting the following dataset:\n",
    "\n",
    "| Property | Value |\n",
    "|:--------:|:-----:|\n",
    "| Dataset  | SWU4  |\n",
    "| N-Subjects  | 454   |\n",
    "| Scans-per-subjects | 2 |\n",
    "| Atlases | Desikan, CPAC200 |\n",
    "| Desikan Nodes | 70 |\n",
    "| CPAC200 Nodes | 200 |\n",
    "\n",
    "The covariates you have are: `SUBID, SESSION, AGE_AT_SCAN_1, SEX, RESTING_STATE_INSTRUCTION, TIME_OF_DAY, SEASON, SATIETY, LMP`. There are other columns in the `.csv` file (downloaded in the next step) but they are populated with a `#` meaning that the value was not recorded.\n",
    "\n",
    "There are several other atlases available - you can change which one you use \n",
    "Running the cell below will get you the data. **Please note, you only have to run these two cells once!!!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Graphs + Covariates\n",
    "Run the following cells of code to load the graphs into your computer, as well as the covariates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: networkx==1.9 in /opt/conda/lib/python3.6/site-packages\r\n",
      "Requirement already satisfied: decorator>=3.4.0 in /opt/conda/lib/python3.6/site-packages (from networkx==1.9)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install networkx==1.9 #networkx broke backwards compatibility with these graph files\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import csv\n",
    "\n",
    "\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/SWU4/desikan\n",
      "Datasets: SWU4 (454)\n",
      "Total Subjects: 454\n"
     ]
    }
   ],
   "source": [
    "# Initializing dataset names\n",
    "dataset_names = 'SWU4'\n",
    "\n",
    "basepath = 'data'\n",
    "\n",
    "# change which atlas you use, here!\n",
    "\n",
    "atlas = 'desikan' # 'desikan' # or 'CPAC200', or 'Talairach'\n",
    "dir_names = basepath + '/' + dataset_names + '/' + atlas\n",
    "#basepath = \"/\"\n",
    "#dir_names = basepath\n",
    "print(dir_names)\n",
    "fs = OrderedDict()\n",
    "fs[dataset_names] = [root + \"/\" + fl for root, dirs, files in os.walk(dir_names)\n",
    "                     for fl in files if fl.endswith(\".gpickle\")]\n",
    "\n",
    "ps = \"data/SWU4/SWU4.csv\"\n",
    "\n",
    "print(\"Datasets: \" + \", \".join([fkey + \" (\" + str(len(fs[fkey])) + \")\"\n",
    "                                for fkey in fs]))\n",
    "print(\"Total Subjects: %d\" % (sum([len(fs[key]) for key in fs])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadGraphs(filenames, verb=False):\n",
    "    \"\"\"\n",
    "    Given a list of files, returns a dictionary of graphs\n",
    "\n",
    "    Required parameters:\n",
    "        filenames:\n",
    "            - List of filenames for graphs\n",
    "    Optional parameters:\n",
    "        verb:\n",
    "            - Toggles verbose output statements\n",
    "    \"\"\"\n",
    "    #  Initializes empty dictionary\n",
    "    gstruct = OrderedDict()\n",
    "    for idx, files in enumerate(filenames):\n",
    "        if verb:\n",
    "            print(\"Loading: \" + files)\n",
    "        #  Adds graphs to dictionary with key being filename\n",
    "        fname = os.path.basename(files)\n",
    "        gstruct[fname] = nx.read_gpickle(files)\n",
    "    return gstruct\n",
    "\n",
    "def constructGraphDict(names, fs, verb=False):\n",
    "    \"\"\"\n",
    "    Given a set of files and a directory to put things, loads graphs.\n",
    "\n",
    "    Required parameters:\n",
    "        names:\n",
    "            - List of names of the datasets\n",
    "        fs:\n",
    "            - Dictionary of lists of files in each dataset\n",
    "    Optional parameters:\n",
    "        verb:\n",
    "            - Toggles verbose output statements\n",
    "    \"\"\"\n",
    "    #  Loads graphs into memory for all datasets\n",
    "    graphs = OrderedDict()\n",
    "    if verb:\n",
    "        print(\"Loading Dataset: \" + names)\n",
    "    # The key for the dictionary of graphs is the dataset name\n",
    "    graphs[names] = loadGraphs(fs[names], verb=verb)\n",
    "    return graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs = constructGraphDict(dataset_names, fs, verb=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "# This gets age and sex, respecitvely.\n",
    "tmp = csv.reader(open(ps,newline='')) # this is the whole phenotype file\n",
    "pheno = OrderedDict()\n",
    "triple = [[t[0].strip(), t[2], int(t[3] == '2')] for t in tmp\n",
    "          if t[3] != '#' and t[2] != '#'][1:]  # female=1->0, male=2->1\n",
    "\n",
    "for idx, trip in enumerate(triple):\n",
    "    pheno[trip[0]] = trip[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## replace with this\n",
    "\n",
    "k = sorted(list(graphs['SWU4'].keys()))\n",
    "k_id = list(key[6:11] for key in k)\n",
    "k_id = k_id[0::2]\n",
    "k_g1 = k[0::2]\n",
    "\n",
    "g1 = []\n",
    "for xx in k_g1:\n",
    "    g1.append(graphs['SWU4'][xx])\n",
    "\n",
    "#Create vectors of labels\n",
    "age = list()\n",
    "sex = list()\n",
    "\n",
    "for key in k_id:\n",
    "    sex.append(pheno[key][1])\n",
    "    age.append(pheno[key][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ASSIGNMENT:  \n",
    "(Code above used to get data in the correct format.  Below is a simple example test string with kind of silly features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Combine features, separate training and test data\n",
    "\n",
    "X = []\n",
    "for i in range(len(g1)):\n",
    "    featvec = []\n",
    "    \n",
    "    matrix = nx.to_numpy_matrix(g1[i], nodelist=sorted(g1[i].nodes())) #this is how you go to a matrix\n",
    "    logmatrix = np.log10(np.sum(matrix,0) + 1)\n",
    "    logmatrix = np.ravel(logmatrix)\n",
    "        \n",
    "    for ii in logmatrix:\n",
    "        featvec.append(ii)\n",
    "        \n",
    "    for ii in nx.clustering(g1[i]).values():\n",
    "        featvec.append(ii)\n",
    "        \n",
    "    featvec.append(nx.node_connectivity(g1[i]))\n",
    "    \n",
    "#     for ii in nx.degree_centrality(g1[i]).values():\n",
    "#         featvec.append(ii)\n",
    "        \n",
    "    for ii in nx.triangles(g1[i]).values():\n",
    "        featvec.append(ii)\n",
    "        \n",
    "#     featvec.append(nx.is_bipartite(g1[i]))\n",
    "    \n",
    "    xsum = np.asarray(np.sum(matrix))\n",
    "    featvec.append(xsum)\n",
    "    \n",
    "    np.shape(featvec)\n",
    "    X.append(featvec)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.56\n",
      "Accuracy: 0.6\n",
      "Accuracy: 0.58\n",
      "Accuracy: 0.58\n",
      "Accuracy: 0.57\n",
      "Accuracy: 0.58\n",
      "Accuracy: 0.57\n",
      "Accuracy: 0.59\n",
      "Accuracy: 0.61\n",
      "Accuracy: 0.58\n",
      "Overall Accuracy: 0.582\n"
     ]
    }
   ],
   "source": [
    "X_train = X[0:100]\n",
    "Y_train = sex[0:100]\n",
    "\n",
    "X_test = X[100:200]\n",
    "Y_test = sex[100:200]\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler  \n",
    "scaler = StandardScaler()  \n",
    "\n",
    "scaler.fit(X_train)  \n",
    "X_train = scaler.transform(X_train)  \n",
    "X_test = scaler.transform(X_test)  \n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "accuracy = []\n",
    "for i in range(10): #performance will change over time\n",
    "    clf = RandomForestClassifier(n_estimators=1000)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    acc = (clf.predict(X_test) == Y_test)\n",
    "#     acc = Y_test\n",
    "#     predicted = clf.predict(X_test)\n",
    "#     for i in range(0,len(Y_test)):\n",
    "#         acc[i] = predicted[i] == Y_test[i]\n",
    "    accval = (float(np.sum(acc))/float(len(Y_test)))\n",
    "    accuracy.append(accval)\n",
    "    print('Accuracy:',accval)\n",
    "\n",
    "print('Overall Accuracy:',str(np.mean(accuracy)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.66\n",
      "Overall Accuracy: 0.66\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "accuracy = []\n",
    "for i in range(1): #performance will change over time\n",
    "    clf = svm.SVC(kernel='rbf')\n",
    "    clf.fit(X_train, Y_train)\n",
    "    acc = (clf.predict(X_test) == Y_test)\n",
    "#     acc = Y_test\n",
    "#     predicted = clf.predict(X_test)\n",
    "#     for i in range(0,len(Y_test)):\n",
    "#         acc[i] = predicted[i] == Y_test[i]\n",
    "    accval = (float(np.sum(acc))/float(len(Y_test)))\n",
    "    accuracy.append(accval)\n",
    "    print('Accuracy:',accval)\n",
    "\n",
    "print('Overall Accuracy:',str(np.mean(accuracy)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.56\n",
      "Overall Accuracy: 0.56\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "accuracy = []\n",
    "for i in range(1): #performance will change over time\n",
    "    clf = SGDClassifier(loss='log')\n",
    "    clf.fit(X_train, Y_train)\n",
    "    acc = (clf.predict(X_test) == Y_test)\n",
    "#     acc = Y_test\n",
    "#     predicted = clf.predict(X_test)\n",
    "#     for i in range(0,len(Y_test)):\n",
    "#         acc[i] = predicted[i] == Y_test[i]\n",
    "    accval = (float(np.sum(acc))/float(len(Y_test)))\n",
    "    accuracy.append(accval)\n",
    "    print('Accuracy:',accval)\n",
    "\n",
    "print('Overall Accuracy:',str(np.mean(accuracy)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.59\n",
      "Accuracy: 0.56\n",
      "Accuracy: 0.61\n",
      "Accuracy: 0.61\n",
      "Accuracy: 0.59\n",
      "Accuracy: 0.6\n",
      "Accuracy: 0.63\n",
      "Accuracy: 0.63\n",
      "Accuracy: 0.61\n",
      "Accuracy: 0.6\n",
      "Overall Accuracy: 0.603\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "accuracy = []\n",
    "for i in range(10): #performance will change over time\n",
    "    clf = GradientBoostingClassifier(n_estimators=1000, learning_rate=1)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    acc = (clf.predict(X_test) == Y_test)\n",
    "#     acc = Y_test\n",
    "#     predicted = clf.predict(X_test)\n",
    "#     for i in range(0,len(Y_test)):\n",
    "#         acc[i] = predicted[i] == Y_test[i]\n",
    "    accval = (float(np.sum(acc))/float(len(Y_test)))\n",
    "    accuracy.append(accval)\n",
    "    print('Accuracy:',accval)\n",
    "\n",
    "print('Overall Accuracy:',str(np.mean(accuracy)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.61\n",
      "Accuracy: 0.64\n",
      "Accuracy: 0.63\n",
      "Accuracy: 0.6\n",
      "Accuracy: 0.61\n",
      "Accuracy: 0.65\n",
      "Accuracy: 0.58\n",
      "Accuracy: 0.64\n",
      "Accuracy: 0.61\n",
      "Accuracy: 0.66\n",
      "Overall Accuracy: 0.623\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "accuracy = []\n",
    "for i in range(10): #performance will change over time\n",
    "    clf = MLPClassifier(hidden_layer_sizes=(100,100), solver='adam', activation='relu')\n",
    "    clf.fit(X_train, Y_train)\n",
    "    acc = (clf.predict(X_test) == Y_test)\n",
    "#     acc = Y_test\n",
    "#     predicted = clf.predict(X_test)\n",
    "#     for i in range(0,len(Y_test)):\n",
    "#         acc[i] = predicted[i] == Y_test[i]\n",
    "    accval = (float(np.sum(acc))/float(len(Y_test)))\n",
    "    accuracy.append(accval)\n",
    "    print('Accuracy:',accval)\n",
    "\n",
    "print('Overall Accuracy:',str(np.mean(accuracy)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a graph\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# convert to numpy\n",
    "matrix = nx.to_numpy_matrix(g1[15], nodelist=sorted(g1[15].nodes())) #this is how you go to a matrix\n",
    "\n",
    "plt.imshow(np.log10(matrix+1))\n",
    "plt.colorbar()\n",
    "plt.title('connectome example')\n",
    "plt.show()\n",
    "\n",
    "#compute mean connectome\n",
    "mean_matrix = np.zeros((70,70),dtype=np.int16)\n",
    "for i in range(0,len(d)):\n",
    "    mean_matrix = mean_matrix + nx.to_numpy_matrix(g1[i], nodelist=sorted(g1[i].nodes()))\n",
    "mean_matrix = mean_matrix / len(g1)\n",
    "\n",
    "plt.imshow(np.log10(mean_matrix+1))\n",
    "plt.colorbar()\n",
    "plt.title('mean connectome')\n",
    "plt.show()\n",
    "\n",
    "#compute sex-conditional connectomes\n",
    "male_matrix = np.zeros((70,70),dtype=np.int16)\n",
    "male_count = 0\n",
    "for i in range(0,len(d)):\n",
    "    if(sex[i] == 0):\n",
    "        male_matrix = male_matrix + nx.to_numpy_matrix(g1[i], nodelist=sorted(g1[i].nodes()))\n",
    "        male_count = male_count + 1\n",
    "male_matrix = male_matrix / male_count\n",
    "\n",
    "plt.imshow(np.log10(male_matrix+1))\n",
    "plt.colorbar()\n",
    "plt.title('male mean connectome')\n",
    "plt.show()\n",
    "\n",
    "female_matrix = np.zeros((70,70),dtype=np.int16)\n",
    "female_count = 0\n",
    "for i in range(0,len(d)):\n",
    "    if(sex[i] == 1):\n",
    "        female_matrix = female_matrix + nx.to_numpy_matrix(g1[i], nodelist=sorted(g1[i].nodes()))\n",
    "        female_count = female_count + 1\n",
    "female_matrix = female_matrix / female_count\n",
    "\n",
    "plt.imshow(np.log10(female_matrix+1))\n",
    "plt.colorbar()\n",
    "plt.title('female mean connectome')\n",
    "plt.show()\n",
    "\n",
    "print(male_count)\n",
    "print(female_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
